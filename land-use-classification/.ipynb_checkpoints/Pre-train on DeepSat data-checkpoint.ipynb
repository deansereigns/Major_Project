{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import several packages that will be used throughout\n",
    "\n",
    "# numeric packages\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "# filesystem and OS\n",
    "import sys, os, time\n",
    "import glob\n",
    "\n",
    "# plotting\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# these magics ensure that external modules that are modified are also automatically reloaded\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/adalbert/nbserver/urban-environments/keras-utils/\")\n",
    "sys.path.append(\"/home/adalbert/nbserver/urban-environments/keras-models/\")\n",
    "\n",
    "from multi_gpu import make_parallel\n",
    "import keras_utils as ku\n",
    "from vgg16 import vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "workdir = \"/home/adalbert/nbserver/tf-workspace/deepsat-experiments/\"\n",
    "os.chdir(workdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data and set up batching "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "\n",
    "train_dir = \"/home/adalbert/data/DeepSat/img/train/\"\n",
    "test_dir = \"/home/adalbert/data/DeepSat/img/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 324000 images belonging to 6 classes.\n",
      "Found 81000 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# Generator for preprocessing images for data augmentation\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def apply_mean(image_data_generator):\n",
    "    \"\"\"Subtracts the VGG dataset mean\"\"\"\n",
    "    image_data_generator.mean = np.array([123.68, 116.779, 103.939], dtype=np.float32).reshape((3, 1, 1))\n",
    "\n",
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=[1,1.2],\n",
    "        vertical_flip=True,\n",
    "        rotation_range=15,\n",
    "        horizontal_flip=True)\n",
    "apply_mean(train_datagen)\n",
    "\n",
    "\n",
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "apply_mean(test_datagen)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, \\\n",
    "                                         batch_size=BATCH_SIZE,\n",
    "                                         target_size=(224,224),\n",
    "                                         shuffle=True)\n",
    "    \n",
    "# this is a similar generator, for validation data\n",
    "test_generator = test_datagen.flow_from_directory(test_dir, \\\n",
    "                                         batch_size=BATCH_SIZE,\n",
    "                                         target_size=(224,224),\n",
    "                                         shuffle=True)\n",
    "\n",
    "# get class labels\n",
    "class2ind = train_generator.class_indices\n",
    "ind2class = {v:k for k,v in class2ind.iteritems()}\n",
    "\n",
    "N_CLASSES = len(ind2class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 224, 224, 3) (100, 6) 0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "for Xbatch, ybatch in train_generator:\n",
    "    print Xbatch.shape, ybatch.shape, Xbatch.min(), Xbatch.max()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define architectures to use\n",
    "Load weights from model pretrained on ImageNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VGG-16, pre-trained on ImageNet\n",
    "Note that the weights are trained on BGR data for this architecture (probably following Caffe's convention). It turns out that they're a good enough starting point even if using RGB images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 15 layers from file into model...\n",
      "conv1_1 conv1_2 conv2_1 conv2_2 conv3_1 conv3_2 conv3_3 conv4_1 conv4_2 conv4_3 conv5_1 conv5_2 conv5_3 dense6 dense7 done.\n",
      "zeropadding2d_1 [] False\n",
      "conv1_1 [-4.2127056, 32.089035] True\n",
      "zeropadding2d_2 [] False\n",
      "conv1_2 [181.08505, 3.7475786] True\n",
      "maxpooling2d_1 [] False\n",
      "zeropadding2d_3 [] False\n",
      "conv2_1 [14.641756, 14.190277] True\n",
      "zeropadding2d_4 [] False\n",
      "conv2_2 [-41.40144, 2.0176735] True\n",
      "maxpooling2d_2 [] False\n",
      "zeropadding2d_5 [] False\n",
      "conv3_1 [-37.128517, 4.3887882] True\n",
      "zeropadding2d_6 [] False\n",
      "conv3_2 [-140.7614, 9.1637173] True\n",
      "zeropadding2d_7 [] False\n",
      "conv3_3 [-395.57758, 6.6994982] True\n",
      "maxpooling2d_3 [] False\n",
      "zeropadding2d_8 [] False\n",
      "conv4_1 [-530.07147, 10.464104] True\n",
      "zeropadding2d_9 [] False\n",
      "conv4_2 [-1102.5334, 15.28837] True\n",
      "zeropadding2d_10 [] False\n",
      "conv4_3 [-1909.0707, 16.342169] True\n",
      "maxpooling2d_4 [] False\n",
      "zeropadding2d_11 [] False\n",
      "conv5_1 [-1379.9353, 23.410946] True\n",
      "zeropadding2d_12 [] False\n",
      "conv5_2 [-1747.6296, 25.530537] True\n",
      "zeropadding2d_13 [] False\n",
      "conv5_3 [-2552.5098, 76.730209] True\n",
      "maxpooling2d_5 [] False\n",
      "flatten_1 [] False\n",
      "dense6 [-14516.828, 323.77954] True\n",
      "dropout_1 [] False\n",
      "dense7 [-6220.6997, 2066.1497] True\n",
      "dropout_2 [] False\n",
      "dense8 [-0.27438939, 0.0] True\n"
     ]
    }
   ],
   "source": [
    "# build the convolutional base of the VGG16 network\n",
    "model = vgg16(n_classes=N_CLASSES, input_shape=(224,224,3), fcn=False)\n",
    "\n",
    "weights_file = \"../vgg16_weights.h5\"\n",
    "model = ku.load_weights_into_model(model, weights_file, transpose_conv=True, \n",
    "                        layers_to_skip=[\"dense8\"])\n",
    "\n",
    "freeze_layers = [] #['conv1', 'conv2']\n",
    "for l in model.layers:\n",
    "    l.trainable = len([x for x in freeze_layers if x in l.name])==0 and \\\n",
    "                    len(l.get_weights())>0\n",
    "\n",
    "for l in model.layers:\n",
    "    print l.name, [x.sum() for x in l.get_weights()], l.trainable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ResNet initialized with ImageNet weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K.image_dim_ordering: tf\n"
     ]
    }
   ],
   "source": [
    "sys.path.append(\"/home/adalbert/nbserver/DeepGold/deep-learning-models/\")\n",
    "\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.models import Model\n",
    "from resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from imagenet_utils import preprocess_input, decode_predictions\n",
    "\n",
    "model = ResNet50(weights='imagenet', include_top=True)\n",
    "\n",
    "model.layers.pop() # Get rid of the classification layer\n",
    "model.outputs = [model.layers[-1].output]\n",
    "model.output_layers = [model.layers[-1]] # added this line in addition to zo7 solution\n",
    "model.layers[-1].outbound_nodes = []\n",
    "\n",
    "newClassificationLayer = Dense(N_CLASSES, activation='softmax')(model.layers[-1].output)\n",
    "model = Model(input=model.input, output=newClassificationLayer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load previously-saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # load model from checkpoint\n",
    "# model_file = \"vgg16-deepsat-best-checkpoint.h5\"\n",
    "\n",
    "# # with tf.device('/cpu:0'):\n",
    "# # load model and weights\n",
    "# model = keras.models.load_model(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spread model computation on multiple GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "GPUS = [0,1,2,3]\n",
    "\n",
    "# this uses the TensorFlow backend to spread computation on multiple GPUs\n",
    "model_gpu = make_parallel(model, GPUS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.__version__, keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Define model behavior with callbacks and compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# callback for a custom learning rate decay schedule\n",
    "\n",
    "LR_DECAY_PER_EPOCH = 2.0 #1.1\n",
    "BASE_LR = 1\n",
    "\n",
    "lr_scheduler = lambda epoch: BASE_LR * LR_DECAY_PER_EPOCH**(-(epoch/10))\n",
    "lr_decay_callback = keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "# callback to checkpoint best model\n",
    "model_checkpoint_callback = ModelCheckpoint(\"resnet-deepsat-imagenet-best-checkpoint.h5\", monitor='val_acc', \\\n",
    "                                      verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "# compile model\n",
    "from keras.optimizers import SGD, RMSprop, Adadelta, Adagrad, Adam\n",
    "model_gpu.compile(loss='categorical_crossentropy', \\\n",
    "              metrics=['accuracy'],\\\n",
    "              optimizer=Adadelta(lr=BASE_LR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Logs to TensorBoard, new one for each run\n",
    "\n",
    "log_path_tensorboard = \"./logs/\"\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "import time\n",
    "\n",
    "now = time.strftime(\"%c\")\n",
    "tensorboard_callback_fn = TensorBoard(log_dir=log_path_tensorboard + now, \\\n",
    "                                histogram_freq=1, \\\n",
    "                                write_graph=True, \\\n",
    "                                write_images=False)\n",
    "\n",
    "# Train model\n",
    "\n",
    "history = model_gpu.fit_generator(\n",
    "            train_generator,\n",
    "            samples_per_epoch=2000,\n",
    "            nb_epoch=50,\n",
    "            validation_data=test_generator,\n",
    "            callbacks = [tensorboard_callback_fn, lr_decay_callback, \\\n",
    "                         model_checkpoint_callback],\n",
    "            nb_val_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(12,4))\n",
    "ax[0].plot(history.history['loss'], label=\"train\")\n",
    "ax[0].plot(history.history['val_loss'], label=\"test\")\n",
    "ax[0].set_title(\"Loss\", fontsize=14)\n",
    "ax[0].set_xlabel(\"Epoch\")\n",
    "ax[0].legend(loc=\"best\")\n",
    "ax[1].plot(history.history['acc'], label=\"train\")\n",
    "ax[1].plot(history.history['val_acc'], label=\"test\")\n",
    "ax[1].set_title(\"Accuracy\", fontsize=14)\n",
    "ax[1].set_xlabel(\"Epoch\")\n",
    "ax[1].legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
